{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I still remember my first day in machine learning class. The first example which was provided to explain, how machine learning works, was “Spam Detection”. I think in most of the machine learning courses tutors provide the same example, but, in how many courses you actually get to implement the model? We talk how machine learning involved in Spam Detection and then just move on to other things.\n",
    "\n",
    "Introduction\n",
    "\n",
    "The idea of this post is to understand step by step working of the spam filter and how it helps in making everyone life easier. Also, next time when you see a “You have won a lottery” email rather than ignoring it, you might prefer to report it as a spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gmail Spam Detection\n",
    "\n",
    "We all know the data Google has, is not obviously in paper files. They have data centers which maintain the customers data. Before Google/Gmail decides to segregate the emails into spam or not spam category, before it arrives to your mailbox, hundreds of rules apply to those email in the data centers. These rules describe the properties of a spam email. \n",
    "There are common types of spam filters which are used by Gmail/Google —\n",
    "\n",
    "# Blatant Blocking- \n",
    "Deletes the emails even before it reaches to the inbox.\n",
    "# Bulk Email Filter- \n",
    "This filter helps in filtering the emails that are passed through other categories but are spam.\n",
    "# Category Filters- \n",
    "User can define their own rules which will enable the filtering of the messages according to the specific content or the email addresses etc.\n",
    "# Null Sender Disposition- \n",
    "Dispose of all messages without an SMTP envelope sender address. Remember when you get an email saying, “Not delivered to xyz address”.\n",
    "# Null Sender Header Tag Validation-\n",
    "Validate the messages by checking security digital signature.\n",
    "\n",
    "There are ways to avoid spam filtering and send your emails straight to the inbox. To learn more about Gmail spam filter please watch this informational video from Google.\n",
    "\n",
    "# Create a Spam Detector : Pre-processing\n",
    "\n",
    "Moving on to our aim of creating our very own spam detector. Let’s talk about about that blue box in the middle of above image. The model is like a small kid unless you tell the kid, the difference between salt and sugar, he/she won’t be able to recognize it. The similar idea we apply on machine learning model, we tell the model beforehand what kind of email can be spam or not spam. In order to do that we need to collect the data from users and ask them to filter few emails as spam or not spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "#Run the below piece of code for the first time\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data = pd.read_csv(r\"C:\\Users\\ankit\\Desktop\\DATA.S\\Spam\\spam.csv\",encoding = \"latin\")\n",
    "message_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data = message_data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data = message_data.rename(columns = {'v1':'Spam/Not_Spam','v2':'message'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam/Not_Spam</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Spam/Not_Spam                                            message\n",
       "0           ham  Go until jurong point, crazy.. Available only ...\n",
       "1           ham                      Ok lar... Joking wif u oni...\n",
       "2          spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3           ham  U dun say so early hor... U c already then say...\n",
       "4           ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spam/Not_Spam</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              message         \\\n",
       "                count unique   \n",
       "Spam/Not_Spam                  \n",
       "ham              4825   4516   \n",
       "spam              747    653   \n",
       "\n",
       "                                                                       \n",
       "                                                             top freq  \n",
       "Spam/Not_Spam                                                          \n",
       "ham                                       Sorry, I'll call later   30  \n",
       "spam           Please call our customer service representativ...    4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data.groupby('Spam/Not_Spam').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data_copy = message_data['message'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "5       FreeMsg Hey there darling it's been 3 week's n...\n",
       "6       Even my brother is not like to speak with me. ...\n",
       "7       As per your request 'Melle Melle (Oru Minnamin...\n",
       "8       WINNER!! As a valued network customer you have...\n",
       "9       Had your mobile 11 months or more? U R entitle...\n",
       "10      I'm gonna be home soon and i don't want to tal...\n",
       "11      SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12      URGENT! You have won a 1 week FREE membership ...\n",
       "13      I've been searching for the right words to tha...\n",
       "14                    I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15      XXXMobileMovieClub: To use your credit, click ...\n",
       "16                             Oh k...i'm watching here:)\n",
       "17      Eh u remember how 2 spell his name... Yes i di...\n",
       "18      Fine if thatåÕs the way u feel. ThatåÕs the wa...\n",
       "19      England v Macedonia - dont miss the goals/team...\n",
       "20              Is that seriously how you spell his name?\n",
       "21      IÛ÷m going to try for 2 months ha ha only joking\n",
       "22      So Ì_ pay first lar... Then when is da stock c...\n",
       "23      Aft i finish my lunch then i go str down lor. ...\n",
       "24      Ffffffffff. Alright no way I can meet up with ...\n",
       "25      Just forced myself to eat a slice. I'm really ...\n",
       "26                         Lol your always so convincing.\n",
       "27      Did you catch the bus ? Are you frying an egg ...\n",
       "28      I'm back &amp; we're packing the car now, I'll...\n",
       "29      Ahhh. Work. I vaguely remember that! What does...\n",
       "                              ...                        \n",
       "5542             Armand says get your ass over to epsilon\n",
       "5543               U still havent got urself a jacket ah?\n",
       "5544    I'm taking derek &amp; taylor to walmart, if I...\n",
       "5545        Hi its in durban are you still on this number\n",
       "5546           Ic. There are a lotta childporn cars then.\n",
       "5547    Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5548                   No, I was trying it all weekend ;V\n",
       "5549    You know, wot people wear. T shirts, jumpers, ...\n",
       "5550          Cool, what time you think you can get here?\n",
       "5551    Wen did you get so spiritual and deep. That's ...\n",
       "5552    Have a safe trip to Nigeria. Wish you happines...\n",
       "5553                          Hahaha..use your brain dear\n",
       "5554    Well keep in mind I've only got enough gas for...\n",
       "5555    Yeh. Indians was nice. Tho it did kane me off ...\n",
       "5556    Yes i have. So that's why u texted. Pshew...mi...\n",
       "5557    No. I meant the calculation is the same. That ...\n",
       "5558                               Sorry, I'll call later\n",
       "5559    if you aren't here in the next  &lt;#&gt;  hou...\n",
       "5560                    Anything lor. Juz both of us lor.\n",
       "5561    Get me out of this dump heap. My mom decided t...\n",
       "5562    Ok lor... Sony ericsson salesman... I ask shuh...\n",
       "5563                                  Ard 6 like dat lor.\n",
       "5564    Why don't you wait 'til at least wednesday to ...\n",
       "5565                                         Huh y lei...\n",
       "5566    REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                Will Ì_ b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first do some pre-processing on message text, like removing - punctuation and stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data_copy = message_data_copy.apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go jurong point crazy Available bugis n great ...\n",
       "1                                 Ok lar Joking wif u oni\n",
       "2       Free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "3                     U dun say early hor U c already say\n",
       "4             Nah dont think goes usf lives around though\n",
       "5       FreeMsg Hey darling 3 weeks word back Id like ...\n",
       "6          Even brother like speak treat like aids patent\n",
       "7       per request Melle Melle Oru Minnaminunginte Nu...\n",
       "8       WINNER valued network customer selected receiv...\n",
       "9       mobile 11 months U R entitled Update latest co...\n",
       "10      Im gonna home soon dont want talk stuff anymor...\n",
       "11      SIX chances win CASH 100 20000 pounds txt CSH1...\n",
       "12      URGENT 1 week FREE membership å£100000 Prize J...\n",
       "13      Ive searching right words thank breather promi...\n",
       "14                                            DATE SUNDAY\n",
       "15      XXXMobileMovieClub use credit click WAP link n...\n",
       "16                                        Oh kim watching\n",
       "17      Eh u remember 2 spell name Yes v naughty make ...\n",
       "18             Fine thatåÕs way u feel ThatåÕs way gota b\n",
       "19      England v Macedonia dont miss goalsteam news T...\n",
       "20                                   seriously spell name\n",
       "21                  IÛ÷m going try 2 months ha ha joking\n",
       "22                         Ì pay first lar da stock comin\n",
       "23      Aft finish lunch go str lor Ard 3 smth lor U f...\n",
       "24                     Ffffffffff Alright way meet sooner\n",
       "25      forced eat slice Im really hungry tho sucks Ma...\n",
       "26                                  Lol always convincing\n",
       "27      catch bus frying egg make tea eating moms left...\n",
       "28       Im back amp packing car Ill let know theres room\n",
       "29               Ahhh Work vaguely remember feel like Lol\n",
       "                              ...                        \n",
       "5542                          Armand says get ass epsilon\n",
       "5543                  U still havent got urself jacket ah\n",
       "5544    Im taking derek amp taylor walmart Im back tim...\n",
       "5545                               Hi durban still number\n",
       "5546                              Ic lotta childporn cars\n",
       "5547    contract mobile 11 Mnths Latest Motorola Nokia...\n",
       "5548                                     trying weekend V\n",
       "5549    know wot people wear shirts jumpers hat belt k...\n",
       "5550                                  Cool time think get\n",
       "5551                   Wen get spiritual deep Thats great\n",
       "5552    safe trip Nigeria Wish happiness soon company ...\n",
       "5553                                 Hahahause brain dear\n",
       "5554    Well keep mind Ive got enough gas one round tr...\n",
       "5555    Yeh Indians nice Tho kane bit shud go 4 drink ...\n",
       "5556                 Yes thats u texted Pshewmissing much\n",
       "5557    meant calculation ltgt units ltgt school reall...\n",
       "5558                                 Sorry Ill call later\n",
       "5559                 arent next ltgt hours imma flip shit\n",
       "5560                              Anything lor Juz us lor\n",
       "5561          Get dump heap mom decided come lowes BORING\n",
       "5562    Ok lor Sony ericsson salesman ask shuhui say q...\n",
       "5563                                   Ard 6 like dat lor\n",
       "5564                dont wait til least wednesday see get\n",
       "5565                                              Huh lei\n",
       "5566    REMINDER O2 get 250 pounds free call credit de...\n",
       "5567    2nd time tried 2 contact u U å£750 Pound prize...\n",
       "5568                          Ì b going esplanade fr home\n",
       "5569                          Pity mood Soany suggestions\n",
       "5570    guy bitching acted like id interested buying s...\n",
       "5571                                       Rofl true name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the pre-processing is done, we would need to vectorize the data — i.e collecting each word and its frequency in each email. The vectorization will produce a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x9376 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 47254 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_mat = vectorizer.fit_transform(message_data_copy)\n",
    "message_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vector matrix can be used create train/test split. This will help us to train the model/machine to be smart and test the accuracy of its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_train, message_test, spam_nospam_train, spam_nospam_test = train_test_split(message_mat, \n",
    "                                                        message_data['Spam/Not_Spam'], test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing a model\n",
    "Now that we have train test split, we would need to choose a model. There is a huge collection of models but for this particular exercise we will be using logistic regression.Why?\n",
    "\n",
    "Generally when someone asks, what is logistic regression? what do you tell them — Oh! it is an algorithm which is used for categorizing things into two classes (most of the time) i.e. the result is measured using a dichotomous variable. But, how does logistic regression classify thing into classes like -binomial(2 possible values), multinomial(3 or more possible values) and ordinal(deals with ordered categories). For this post we will only be focusing on binomial logistic regression i.e. the outcome of the model will be categorized into two classes.\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "According to Wikipedia definition,\n",
    "Logistic Regression measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function.\n",
    "\n",
    "From the definition it seems, the logistic function plays an important role in classification here but we need to understand what is logistic function and how does it help in estimating the probability of being in a class.\n",
    "\n",
    "                         phi(z)=1/1+exponential(-z)\n",
    "\n",
    "The formula mentioned in the above image is known as Logistic function or Sigmoid function and the curve called Sigmoid curve. The Sigmoid function gives an S shaped curve. The output of Sigmoid function tends towards 1 as z → ∞ and tends towards 0 as z → −∞. Hence Sigmoid/logistic function produces the value of dependent variable which will always lie between [0,1] i.e the probability of being in a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "For the Spam detection problem, we have tagged messages but we are not certain about new incoming messages. We will need a model which can tell us the probability of a message being Spam or Not Spam. Assuming in this example , 0 indicates — negative class (absence of spam) and 1 indicates — positive class (presence of spam), we will use logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9383971291866029"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Spam_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "Spam_model.fit(message_train, spam_nospam_train)\n",
    "pred = Spam_model.predict(message_test)\n",
    "accuracy_score(spam_nospam_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, first we define the model then fit the train data — this phase is called training your model. Once the training phase is finished we can use the test split and predict the results. In order to check the accuracy of our model we can use accuracy score metric. This metric compares the predicted results with the obtained true results. After running above code we got 93% accuracy.\n",
    "In some cases 93% might seems a good score. There are a lot other things we can do with the collected data in order to achieve more accurate results, like stemming the words and normalizing the length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try using stemming and normalizing length of the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer (text):\n",
    "    text = text.split()\n",
    "    words = \"\"\n",
    "    for i in text:\n",
    "            stemmer = SnowballStemmer(\"english\")\n",
    "            words += (stemmer.stem(i))+\" \"\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data_copy = message_data_copy.apply(stemmer)\n",
    "vectorizer = TfidfVectorizer(\"english\")\n",
    "message_mat = vectorizer.fit_transform(message_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_train, message_test, spam_nospam_train, spam_nospam_test = train_test_split(message_mat, \n",
    "                                                        message_data['Spam/Not_Spam'], test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9461722488038278"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Spam_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "Spam_model.fit(message_train, spam_nospam_train)\n",
    "pred = Spam_model.predict(message_test)\n",
    "accuracy_score(spam_nospam_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy score improved. Let's try normalizing length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam/Not_Spam</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Spam/Not_Spam                                            message  length\n",
       "0           ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1           ham                      Ok lar... Joking wif u oni...      29\n",
       "2          spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3           ham  U dun say so early hor... U c already then say...      49\n",
       "4           ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data['length'] = message_data['message'].apply(len)\n",
    "message_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "length = message_data['length'].as_matrix()\n",
    "new_mat = np.hstack((message_mat.todense(),length[:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_train, message_test, spam_nospam_train, spam_nospam_test = train_test_split(new_mat, \n",
    "                                                        message_data['Spam/Not_Spam'], test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9467703349282297"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Spam_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "Spam_model.fit(message_train, spam_nospam_train)\n",
    "pred = Spam_model.predict(message_test)\n",
    "accuracy_score(spam_nospam_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "As we saw, we used previously collected data in order to train the model and predicted the category for new incoming emails. This indicate the importance of tagging the data in right way. One mistake can make your machine dumb, e.g In your gmail or any other email account when you get the emails and you think it is a spam but you choose to ignore, may be next time when you see that email, you should report that as a spam. This process can help a lot of other people who are receiving the same kind of email but not aware of what spam is. Sometimes wrong spam tag can move a genuine email to spam folder too. So, you have to be careful before you tag an email as a spam or not spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
